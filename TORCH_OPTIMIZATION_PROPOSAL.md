# ğŸ¯ mflux Torch ä¾èµ–ä¼˜åŒ–ææ¡ˆ

## ğŸ“Š å®é™…æ•°æ®éªŒè¯

### Torch çœŸå®å ç”¨ç©ºé—´

**ä¸‹è½½å¤§å° (Wheel æ–‡ä»¶)**:
- macOS ARM64: **~75 MB** (å‡ºä¹æ„æ–™çš„å°ï¼)
- åŒ…å« CPU-only è¿ç®—åº“

**å®‰è£…åç£ç›˜å ç”¨**:
- Wheel è§£å‹å: ~150-200 MB
- åŠ ä¸Šä¾èµ– (numpy, typing-extensions ç­‰): ~250-300 MB
- å¦‚æœåŒ…å« CUDA ç‰ˆæœ¬: 2-3 GB âš ï¸

**å…³é”®å‘ç°**:
- âœ… macOS ARM64 çš„ torch é»˜è®¤å°±æ˜¯ **CPU-only** ç‰ˆæœ¬
- âœ… å·²ç»ç›¸å¯¹ç²¾ç®€ (~300 MB æ€»å ç”¨)
- âœ… ä¸éœ€è¦ç‰¹æ®Šçš„"ç²¾ç®€ç‰ˆ"

---

## ğŸ” mflux çš„ torch ä½¿ç”¨åˆ†ææ€»ç»“

### å®é™…ä½¿ç”¨çš„åŠŸèƒ½ (éå¸¸æœ‰é™)

```python
# 1. åŠ è½½æƒé‡æ–‡ä»¶
torch.load("model.pt", map_location="cpu")  # ä»… 1 å¤„ä½¿ç”¨

# 2. åŸºç¡€å¼ é‡æ“ä½œ
tensor.to(torch.float16)      # ç±»å‹è½¬æ¢
tensor.detach().cpu()         # ç§»åˆ° CPU
tensor.numpy()                # è½¬ numpy
torch.Tensor ç±»å‹åˆ¤æ–­          # ç±»å‹æ£€æŸ¥

# 3. ç®€å•æ•°å­¦è¿ç®—
torch.all(tensor)             # å¸ƒå°”è¿ç®—
torch.split(tensor, sizes)    # åˆ†å‰²
torch.chunk(tensor, chunks)   # åˆ†å—

# 4. transformers æ¨¡å‹åŠ è½½
Qwen3VLForConditionalGeneration.from_pretrained(
    dtype=torch.bfloat16  # ä»…ç”¨äºæŒ‡å®šæ•°æ®ç±»å‹
)
```

**ä¸ä½¿ç”¨çš„åŠŸèƒ½**:
- âŒ ç¥ç»ç½‘ç»œå±‚ (nn.Module, nn.Linear ç­‰)
- âŒ è‡ªåŠ¨å¾®åˆ† (requires_grad, backward)
- âŒ ä¼˜åŒ–å™¨ (Adam, SGD ç­‰)
- âŒ GPU/CUDA è¿ç®—
- âŒ åˆ†å¸ƒå¼è®­ç»ƒ
- âŒ TorchScript/JIT
- âŒ æ•°æ®åŠ è½½å™¨ (DataLoader)

---

## ğŸ’¡ ä¼˜åŒ–æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | èŠ‚çœç©ºé—´ | å…¼å®¹æ€§ | å®æ–½éš¾åº¦ | æ¨èåº¦ |
|------|----------|--------|----------|--------|
| **æ–¹æ¡ˆ 0: ä¿æŒç°çŠ¶** | 0 MB | 100% | - | â­â­â­ |
| **æ–¹æ¡ˆ 1: æ‹†åˆ†å¯é€‰ä¾èµ–** | 0-300 MB* | 100% | ä½ | â­â­â­â­â­ |
| **æ–¹æ¡ˆ 2: å»¶è¿Ÿå¯¼å…¥ + é™çº§æç¤º** | 0-300 MB* | 95% | ä½ | â­â­â­â­ |
| **æ–¹æ¡ˆ 3: ç”¨ numpy æ›¿æ¢** | ~300 MB | 80% | é«˜ | â­â­ |
| **æ–¹æ¡ˆ 4: å®Œå…¨ç§»é™¤ torch** | ~300 MB | 60% | å¾ˆé«˜ | â­ |

*å–å†³äºç”¨æˆ·æ˜¯å¦å®‰è£…å¯é€‰åŠŸèƒ½

---

## ğŸ¯ æ¨èæ–¹æ¡ˆ: æ‹†åˆ†å¯é€‰ä¾èµ–

### æ ¸å¿ƒç†å¿µ
- **ä¸ç‰ºç‰²åŠŸèƒ½**ï¼Œåªæ˜¯è®©ç”¨æˆ·é€‰æ‹©éœ€è¦ä»€ä¹ˆ
- **æœ€å°åŒ–é»˜è®¤å®‰è£…**ï¼Œæä¾›å¢é‡å®‰è£…é€‰é¡¹
- **å‘åå…¼å®¹**ï¼Œç°æœ‰ç”¨æˆ·ä¸å—å½±å“

### å®æ–½ç»†èŠ‚

#### 1. ä¿®æ”¹ `pyproject.toml`

```toml
[project]
name = "mflux"
dependencies = [
    "accelerate>=0.31.0",
    "huggingface-hub>=0.24.5,<1.0",
    "mlx>=0.27.0,<0.31.0",
    "numpy>=2.0.1,<3.0",
    "safetensors>=0.4.4,<1.0",
    # ... å…¶ä»–æ ¸å¿ƒä¾èµ–

    # âŒ ç§»é™¤å¼ºåˆ¶çš„ torch ä¾èµ–
    # "torch>=2.3.1,<3.0",
]

[project.optional-dependencies]
# åŸºç¡€æƒé‡è½¬æ¢ï¼ˆæ”¯æŒå¤§éƒ¨åˆ†æ¨¡å‹ï¼‰
weights = [
    "torch>=2.3.1,<3.0; python_version<'3.13'",
    "torch>=2.8.0,<3.0; python_version>='3.13'",
]

# VLM æ¨¡å‹æ”¯æŒ (FIBO-VLM, Qwen-VL)
vlm = [
    "torch>=2.3.1,<3.0; python_version<'3.13'",
    "torch>=2.8.0,<3.0; python_version>='3.13'",
    "transformers>=4.57,<5.0",
]

# Depth Pro æ¨¡å‹æ”¯æŒ
depth = [
    "torch>=2.3.1,<3.0; python_version<'3.13'",
    "torch>=2.8.0,<3.0; python_version>='3.13'",
]

# LoRA æƒé‡è½¬æ¢
lora = [
    "torch>=2.3.1,<3.0; python_version<'3.13'",
    "torch>=2.8.0,<3.0; python_version>='3.13'",
]

# å®Œæ•´åŠŸèƒ½ï¼ˆå‘åå…¼å®¹ï¼‰
all = [
    "mflux[weights,vlm,depth,lora]",
]

# å¼€å‘ä¾èµ–
dev = [
    "mflux[all]",
    "pytest>=8.3.0,<9.0",
    # ...
]
```

#### 2. æ·»åŠ è¿è¡Œæ—¶æ£€æŸ¥

åˆ›å»º `src/mflux/compat/torch_check.py`:

```python
"""
Torch compatibility and optional dependency checking.
"""

_TORCH_AVAILABLE = None
_TORCH_ERROR = None


def is_torch_available() -> bool:
    """Check if torch is available."""
    global _TORCH_AVAILABLE, _TORCH_ERROR
    if _TORCH_AVAILABLE is not None:
        return _TORCH_AVAILABLE

    try:
        import torch
        _TORCH_AVAILABLE = True
        return True
    except ImportError as e:
        _TORCH_ERROR = e
        _TORCH_AVAILABLE = False
        return False


def require_torch(feature_name: str = "this feature"):
    """
    Raise a helpful error if torch is not available.

    Args:
        feature_name: Name of the feature requiring torch

    Raises:
        ImportError: With installation instructions
    """
    if not is_torch_available():
        raise ImportError(
            f"\n{'='*70}\n"
            f"âŒ {feature_name} requires PyTorch, but it's not installed.\n\n"
            f"To install PyTorch support:\n"
            f"  pip install mflux[weights]      # Basic weight conversion\n"
            f"  pip install mflux[vlm]          # VLM models (FIBO-VLM, Qwen)\n"
            f"  pip install mflux[lora]         # LoRA conversion\n"
            f"  pip install mflux[all]          # All features\n"
            f"\nOr install torch directly:\n"
            f"  pip install torch\n"
            f"{'='*70}\n"
        ) from _TORCH_ERROR


def optional_import_torch():
    """
    Optionally import torch with graceful fallback.

    Returns:
        torch module or None
    """
    if is_torch_available():
        import torch
        return torch
    return None
```

#### 3. ä¿®æ”¹æƒé‡å¤„ç†æ–‡ä»¶

**ç¤ºä¾‹: `qwen_weight_handler.py`**

```python
import mlx.core as mx
from safetensors.mlx import load_file as mlx_load_file
from safetensors.torch import load_file as torch_load_file

from mflux.compat.torch_check import require_torch, optional_import_torch

class QwenWeightHandler:
    @staticmethod
    def _load_safetensors_shards(path: Path, loading_mode: str = "multi_glob"):
        # ... existing code ...

        # å½“éœ€è¦ torch fallback æ—¶æ£€æŸ¥
        try:
            file_weights = mlx_load_file(str(file_path))
        except Exception:
            # éœ€è¦ torch ä½œä¸ºåå¤‡
            require_torch("Qwen weight loading (torch fallback)")
            torch = optional_import_torch()

            torch_weights = torch_load_file(str(file_path))
            file_weights = {}
            for name, tensor in torch_weights.items():
                if tensor.dtype == torch.bfloat16:
                    tensor = tensor.to(torch.float32)
                file_weights[name] = mx.array(tensor.numpy())

        # ... rest of code ...
```

**ç¤ºä¾‹: `fibo_vlm_weight_handler.py`**

```python
import mlx.core as mx

from mflux.compat.torch_check import require_torch, optional_import_torch

class FIBOVLMWeightHandler:
    @staticmethod
    def load_vlm_regular_weights(repo_id: str = "briaai/FIBO-vlm", ...):
        # æ˜ç¡®è¦æ±‚ torch
        require_torch("FIBO-VLM model loading")

        torch = optional_import_torch()
        from transformers import Qwen3VLForConditionalGeneration

        model = Qwen3VLForConditionalGeneration.from_pretrained(
            pretrained_model_name_or_path=pretrained_path,
            dtype=torch.bfloat16,
            local_files_only=True,
        )
        # ... rest of code ...
```

**ç¤ºä¾‹: `lora_converter.py`**

```python
import mlx.core as mx
from safetensors import safe_open

from mflux.compat.torch_check import require_torch, optional_import_torch

class LoRAConverter:
    @staticmethod
    def load_weights(lora_path: str) -> dict:
        require_torch("LoRA weight conversion")

        torch = optional_import_torch()
        state_dict = LoRAConverter._load_pytorch_weights(lora_path)
        # ... rest of code ...
```

#### 4. æ›´æ–°æ–‡æ¡£

**README.md æ·»åŠ å®‰è£…é€‰é¡¹**:

```markdown
## ğŸ“¦ Installation

### Basic Installation (MLX models only)
```bash
pip install mflux
```

### With Weight Conversion Support
```bash
# For most models (FLUX, FIBO, Qwen, etc.)
pip install mflux[weights]

# For VLM models (FIBO-VLM, Qwen-VL)
pip install mflux[vlm]

# For LoRA conversion
pip install mflux[lora]

# Full installation (all features)
pip install mflux[all]
```

### ğŸ’¾ Disk Space Requirements

| Installation Type | Disk Space | Supported Features |
|-------------------|------------|-------------------|
| Basic (`mflux`) | ~200 MB | Pre-converted MLX models |
| With weights (`mflux[weights]`) | ~500 MB | Most weight conversions |
| VLM support (`mflux[vlm]`) | ~1.5 GB | Vision-language models |
| Full (`mflux[all]`) | ~1.5 GB | All features |
```

---

## ğŸ“ˆ é¢„æœŸæ”¶ç›Š

### å¯¹ç”¨æˆ·çš„å¥½å¤„

1. **æ›´å¿«çš„å®‰è£…** (åŸºç¡€å®‰è£…)
   - ä¸‹è½½: å‡å°‘ ~75 MB
   - å®‰è£…æ—¶é—´: å‡å°‘ ~30%

2. **æ›´å°çš„ Docker é•œåƒ**
   ```dockerfile
   # åŸºç¡€é•œåƒ: åªç”¨ MLX æ¨ç†
   RUN pip install mflux
   # èŠ‚çœ ~300 MB
   ```

3. **æ›´æ¸…æ™°çš„ä¾èµ–**
   - ç”¨æˆ·çŸ¥é“æ¯ä¸ªåŠŸèƒ½éœ€è¦ä»€ä¹ˆ
   - é¿å…ä¸å¿…è¦çš„ä¾èµ–

4. **å‘åå…¼å®¹**
   - ç°æœ‰ç”¨æˆ·å¯ä»¥ç»§ç»­ä½¿ç”¨ `pip install mflux[all]`
   - æ–°ç”¨æˆ·å¯ä»¥é€‰æ‹©ç²¾ç®€å®‰è£…

### å¯¹é¡¹ç›®çš„å¥½å¤„

1. **æ›´æ¨¡å—åŒ–çš„æ¶æ„**
   - æ¸…æ™°çš„åŠŸèƒ½è¾¹ç•Œ
   - æ›´å®¹æ˜“æµ‹è¯•

2. **æ›´å®¹æ˜“ç§»æ¤**
   - å¯ä»¥åœ¨ä¸æ”¯æŒ torch çš„å¹³å°è¿è¡ŒåŸºç¡€åŠŸèƒ½
   - ä¸ºæœªæ¥æ›¿æ¢ torch é“ºè·¯

3. **æ›´å¥½çš„é”™è¯¯æç¤º**
   - ç”¨æˆ·çŸ¥é“ç¼ºå°‘ä»€ä¹ˆä¾èµ–
   - æ¸…æ™°çš„å®‰è£…æŒ‡å¼•

---

## ğŸš€ å®æ–½è·¯çº¿å›¾

### Phase 1: å‡†å¤‡é˜¶æ®µ (ä¸ç ´åç°æœ‰åŠŸèƒ½)
- [ ] åˆ›å»º `torch_check.py` å…¼å®¹å±‚
- [ ] æ·»åŠ è¿è¡Œæ—¶æ£€æŸ¥åˆ°æ‰€æœ‰ torch ä½¿ç”¨ç‚¹
- [ ] æ›´æ–°æµ‹è¯•ç¡®ä¿å…¼å®¹æ€§
- [ ] åœ¨ CI ä¸­æµ‹è¯•å¯é€‰ä¾èµ–åœºæ™¯

### Phase 2: å‘å¸ƒè¿‡æ¸¡ç‰ˆæœ¬
- [ ] æ›´æ–° `pyproject.toml`ï¼Œtorch ä»åœ¨ dependencies ä¸­
- [ ] åœ¨æ–‡æ¡£ä¸­æ·»åŠ å…³äºå¯é€‰ä¾èµ–çš„è¯´æ˜
- [ ] å‘å¸ƒè¯´æ˜ä¸­å‘ŠçŸ¥ç”¨æˆ·å³å°†çš„å˜åŒ–

### Phase 3: æ­£å¼æ‹†åˆ† (Breaking Change)
- [ ] å°† torch ç§»åˆ° optional-dependencies
- [ ] æ›´æ–°æ‰€æœ‰æ–‡æ¡£å’Œç¤ºä¾‹
- [ ] å‘å¸ƒä¸»ç‰ˆæœ¬æ›´æ–° (ä¾‹å¦‚ 0.13.0 â†’ 0.14.0)

### Phase 4: æŒç»­ä¼˜åŒ–
- [ ] ç›‘æ§ç”¨æˆ·åé¦ˆ
- [ ] è€ƒè™‘è¿›ä¸€æ­¥ä¼˜åŒ– (numpy æ›¿æ¢ç­‰)
- [ ] æ·»åŠ è‡ªåŠ¨å®‰è£…æç¤º

---

## âš ï¸ é£é™©ä¸ç¼“è§£

| é£é™© | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|---------|
| ç”¨æˆ·ä¸çŸ¥é“å®‰è£…å“ªä¸ªç‰ˆæœ¬ | ä¸­ | æ¸…æ™°çš„æ–‡æ¡£ + å‹å¥½çš„é”™è¯¯æç¤º |
| CI/CD éœ€è¦æ›´æ–° | ä½ | ä½¿ç”¨ `[all]` åœ¨ CI ä¸­ |
| å‘åä¸å…¼å®¹ | é«˜ | ä¸»ç‰ˆæœ¬æ›´æ–° + è¯¦ç»†çš„è¿ç§»æŒ‡å— |
| å¢åŠ ç»´æŠ¤å¤æ‚åº¦ | ä¸­ | è‰¯å¥½çš„æµ‹è¯•è¦†ç›– |

---

## ğŸ¬ ç¤ºä¾‹åœºæ™¯

### åœºæ™¯ 1: åªæƒ³ç”¨é¢„è½¬æ¢çš„ MLX æ¨¡å‹

```bash
pip install mflux
mflux-generate --model username/flux-schnell-mlx --prompt "test"
# âœ… å·¥ä½œæ­£å¸¸ï¼Œåªç”¨ ~200 MB
```

### åœºæ™¯ 2: éœ€è¦è½¬æ¢ HuggingFace æƒé‡

```bash
pip install mflux[weights]
mflux-save --model black-forest-labs/FLUX.1-schnell
# âœ… å¯ä»¥è½¬æ¢æƒé‡
```

### åœºæ™¯ 3: ä½¿ç”¨ VLM åŠŸèƒ½

```bash
pip install mflux[vlm]
mflux-generate-fibo --prompt "æè¿°è¿™å¼ å›¾ç‰‡" --image photo.jpg
# âœ… å®Œæ•´ VLM åŠŸèƒ½
```

### åœºæ™¯ 4: å¼€å‘è€… (éœ€è¦æ‰€æœ‰åŠŸèƒ½)

```bash
pip install mflux[all]
# æˆ–è€…
pip install -e ".[all]"
# âœ… å®Œæ•´åŠŸèƒ½ï¼Œå‘åå…¼å®¹
```

---

## ğŸ“ ç»“è®º

è™½ç„¶ torch æœ¬èº«åªå  ~300 MB (macOS ARM64)ï¼Œä½†é€šè¿‡**å¯é€‰ä¾èµ–**çš„æ–¹å¼ï¼š

1. âœ… **ç»™ç”¨æˆ·é€‰æ‹©æƒ** - æ ¹æ®éœ€æ±‚å®‰è£…
2. âœ… **ä¼˜åŒ–å®‰è£…ä½“éªŒ** - åŸºç¡€å®‰è£…æ›´å¿«
3. âœ… **æé«˜ä»£ç è´¨é‡** - æ¨¡å—åŒ–ã€æ¸…æ™°çš„ä¾èµ–å…³ç³»
4. âœ… **å‘åå…¼å®¹** - ä¸ç ´åç°æœ‰å·¥ä½œæµ
5. âœ… **ä¸ºæœªæ¥é“ºè·¯** - å¯ä»¥é€æ­¥ç”¨å…¶ä»–æ–¹æ¡ˆæ›¿æ¢

**å»ºè®®**: é‡‡ç”¨æ­¤æ–¹æ¡ˆï¼Œåœ¨ä¸‹ä¸€ä¸ªä¸»ç‰ˆæœ¬æ›´æ–° (å¦‚ v0.13.0) ä¸­å®æ–½ã€‚
